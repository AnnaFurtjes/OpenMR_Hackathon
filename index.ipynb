{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "require(knitr)\n",
                "opts_knit$set(root.dir = \"C:/Users/k1894405/Documents/GitHub/OpenMR_Hackathon/input\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "Welcome to our data visualisation workshop in R!\n",
                "<br/>\n",
                "This tutorial aims to mirror [Stijn Denissen's visualisation workshop](https://github.com/OpenMRBenelux/openmr2021-dataviz-workshop) in Python using neuroimaging data. Ideas and explanations have been adapted from this tutorial. \n",
                "<br/>\n",
                "\n",
                "The neuroimaging data used here is part of an open source repository on adult language learners. We express our sincere gratitude to Kshipra Gurunandan, Manuel Carreiras and Pedro M. Paz-Alonso for making this data open source, and thus allowing us to make this tutorial.\n",
                "\n",
                "***\n",
                "\n",
                "# What is a Jupyter Notebook?\n",
                "\n",
                "A jupyter notebook:\n",
                "\n",
                "  - is a convenient way to combine code and output with neat documentation, allowing others to easily follow a project that uses code\n",
                "  - works with so-called \"blocks\", which can either be a \"code block\" or a \"markdown block\"\n",
                "  \n",
                "    - Markdown block: You are reading one right now! It is a block that understands the markdown language, an easy language to create text, similar to HTML and LaTeX.\n",
                "    - Code block: A code block in a jupyter notebook understands the Python language by default. If applicable, output is printed below the code block, such as images and text. You can also change the kernel of code blocks; in this way you can use other programming languages in the code blocks! Read more about this [here](https://jupyter4edu.github.io/jupyter-edu-book/jupyter.html).\n",
                "  - Allows to cross-reference between cells has some nice shortcuts:\n",
                "\n",
                "|Operation|Shortcut|\n",
                "|---|---|\n",
                "|Run a cell|shift + enter / ctrl + enter|\n",
                "|Add cell above | \"a\" (first click left of the cell)|\n",
                "|Add cell below | \"b\" (first click left of the cell)|\n",
                "|Copy cell: | \"c\" (first click left of the cell)|\n",
                "|Cut cell: | \"x\" (first click left of the cell)|\n",
                "|Paste cell | \"v\" (first click left of the cell)|\n",
                "|Delete cell | \"dd\" (first click left of the cell)|\n",
                "|Comment out code | select code and press ctrl + / or cmd + /|\n",
                "|Uncomment code| select code and press ctrl + / or cmd + /|\n",
                "|Help and documentation| type `?` or `help()` in a code cell|\n",
                "\n",
                "\n",
                "***\n",
                "\n",
                "# Preparations\n",
                "<br/>\n",
                "\n",
                "\n",
                "## Load dependencies\n",
                "\n",
                "Import the packages providing specialised functions that will make manipulating your data easier or even possible in the first place. These packages must have been previously installed using `install.packages()`. Now, we load them using `library()`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load package to read and manipulate nifti files\n",
                "library(oro.nifti)\n",
                "\n",
                "# load tractor.package specialised on visualising anatomical images\n",
                "library(tractor.base)\n",
                "\n",
                "# load package specialised on fmri visualisation\n",
                "#Polzehl, J. and Tabelow, K. (2007) fmri: A Package for Analyzing fmri Data, R News, 7:13-17 .\n",
                "library(fmri)\n",
                "# required for three-dimensional plotting of fmri data\n",
                "library(tkrplot) \n",
                "\n",
                "# load data cleaning package\n",
                "library(stringr)\n",
                "\n",
                "# load package to read .json file\n",
                "library(rjson)\n",
                "\n",
                "# load data display package\n",
                "library(tableone)\n",
                "\n",
                "# load data visualisation package\n",
                "library(ggplot2)\n",
                "\n",
                "# load package for stat_cor function used in plots\n",
                "library(ggpubr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Origins of the data we are using\n",
                "Study design:\n",
                "\n",
                "34 adult language learners aged 20-70 were recruited from a language school. Subjects were at either intermediate or advanced levels of learning the same second language. Subjects performed semantic comprehension (reading and speech) and verbal production tasks in the MRI scanner in their native and new languages.\n",
                "\n",
                "***\n",
                "# 1. Anatomical MRI images\n",
                "\n",
                "The data was downloaded from OpenNeuro, [project ds003542](https://openneuro.org/datasets/ds003542/versions/1.0.0), which originates from a study on language learners. For the neuro-imaging data part, we only extracted data from subject 1. Hence, the data is present in the \"inputs/ds00352\" folder, subdirectory \"sub-01\":\n",
                "\n",
                "  - Anatomical MRI: \"anat\" subfolder\n",
                "  - Functional MRI: \"func\" subfolder\n",
                "\n",
                "## 1.1 The **Brain Imaging Data Structure** (BIDS) data organisation\n",
                "\n",
                "To unify neuroimaging studies, the BIDS data organisation is a popular approach to organise your data in a reproducible way. Find out more [here](https://bids.neuroimaging.io/). \n",
                "\n",
                "Briefly, BIDS aims to unify neuro-imaging (meta)data organisation and sharing; essentially speaking the same language when it comes to neuro-imaging data.\n",
                "\n",
                "## 1.2 What is a NIfTI (.nii)?\n",
                "Most neuroimages are saved in a *NIfTI* file. NIfTI is a nice informatic tool for neuro-imaging data, and easy to work with. For a thorough explanation on the origin and objective of NIfTI, we refer to this [webpage](https://nifti.nimh.nih.gov/). \n",
                "\n",
                "\n",
                "## 1.3 Visualising anatomical MRI images\n",
                "\n",
                "Nifti files with a .gz extension need to be unzipped so R can read them in. We do this using the R.utils package which provides the `gunzip()` function.\n",
                "\n",
                "  1. First, we load the package using the `library()` function.\n",
                "  \n",
                "  2. Set the working directory using `setwd()` to where your anatomical nifi file is saved.\n",
                "  \n",
                "  3. Use the `gunzip()` function to unzip the file. \n",
                "  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load the R.utils package\n",
                "library(R.utils)\n",
                "# set the working directory\n",
                "setwd(paste0(temporarywd,\"/ub-01/anat\"))\n",
                "# unzip anatomical file\n",
                "gunzip(\"sub-01_anat_sub-01_T1w.nii.gz\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are many packages in R designed to manipulate nifti images in R. A popular one is the oro.nifti package. This tutorial does not even scratch the surface of what this package can do and we recommend checking out the [documentation](https://www.rdocumentation.org/packages/oro.nifti/versions/0.11.0). \n",
                "\n",
                "Here, we will use the package to display the brain scan of our subject. We don't have to load the library of functions because we have already done this above in the *Preparations*.\n",
                "\n",
                "  1. Set your working directory and read in the image using the `readNIfTI()` function. \n",
                "  2. Calibrate the image using the `cal_img()` function\n",
                "  3. Display the data structure of your nifti file using the `print()` function.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporarywd <- getwd()\n",
                "setwd(paste0(temporarywd,\"/ub-01/anat\"))\n",
                "\n",
                "# read nifti file\n",
                "anat_img <- readNIfTI(\"sub-01_anat_sub-01_T1w.nii\")\n",
                "\n",
                "# Set Max/Min for nifti object by range of data to get right format\n",
                "anat_img = cal_img(anat_img)\n",
                "\n",
                "# see information about nifti header\n",
                "print(anat_img)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's use two functions in the oro.nifti package es has two functions for displaying the brain image:\n",
                "\n",
                "  1. The `image()` function displays all the axial brain slices saved in the nifti image.\n",
                "  2. The `orthographic()` function allows you to display your image from mid-axial, mid-sagittal and mid-coronal perspectives.\n",
                "  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prints loads of brains on a black background\n",
                "image(anat_img) \n",
                "# mid-axial, mid-sagittal, mid-coronal views\n",
                "orthographic(anat_img) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The tractor.base package is another popular package for neuro-visualisation in R. It can read and write popular file formats, perform interactive and non-interactive visualisation, flexible image manipulation, metadata and sparse image handling. Find out more [here](http://www.tractor-mri.org.uk/).\n",
                "<br/>\n",
                "\n",
                "We are going to use this package to simply display the brain image from an axial, sagittal and coronal perspective. Like with the oro.nifti package, there is no need to load the library, because we have already done this in the *Preparations*.\n",
                "\n",
                "<br/>\n",
                "Use the `createSliceGraphic()` function to display the brain image. By specifying the x (sagittal view), y (coronal view), and z (axial view) argument, you can choose the slide you would like to be displayed. \n",
                "Here, we display the 100th slice in the sagittal view, and the 150th slide in the coronal and axial views. We choose for the image to be disolayed on the default graphics device using the `device = \"internal\"` argument.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "createSliceGraphic(anat_img,x=100, device=\"internal\")\n",
                "createSliceGraphic(anat_img,y=150, device=\"internal\")\n",
                "createSliceGraphic(anat_img,z=150, device=\"internal\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tractor.base also provides an equivalent function to the `orthographic()` in oro.nifti, which displays all slices saved in the nifti file. It's the `createContactSheetGraphic()` function for which you can choose whether to get an axial, coronal or sagittal view using the `axis` argument. \n",
                "Let's go ahead and create a sagittal (`axis = 1`) contact sheet. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "createContactSheetGraphic(anat_img,axis=1,device=\"internal\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***\n",
                "\n",
                "# 2. Functional MRI\n",
                "\n",
                "Compared with an anatomical MRI image, a functional MRI image has a fourth dimension: time!\n",
                "There is specialised package in R called fmri which allows you to plot easily plot functional neuroimaging data using the `plot.fmridata()` function. There is no need to load the fmri package (and the tkrplot package which is needed for the plot fuction) because both already have been loaded in the preparations. \n",
                "\n",
                "  1. First, we set the working directory to where the functional image is saved.\n",
                "  2. Second, we read in the file using the `read.NIFTI()` function provided by the fmri package.\n",
                "  3. Finally, we use the `plot.fmridata()` function to plot the data. It will bring up an interactive window in which you can explore your image, and get a 3D representation of how your BOLD signal changed over time.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporarywd<-getwd()\n",
                "setwd(paste0(temporarywd,\"/ub-01/func\"))\n",
                "func_img<-read.NIFTI(\"sub-01_func_sub-01_task-compL1_run-1_bold.nii\",level=0.75)\n",
                "\n",
                "\n",
                "# this function brings up an interactive window to explore the fmri image\n",
                "plot.fmridata(func_img, anatomic = F, maxpvalue = 0.05,\n",
                "              spm = TRUE, pos = c(100, 150, 150), type = \"slice\",\n",
                "              slice =  1, view = \"axial\" ,zlim.u =\n",
                "              NULL, zlim.o = NULL,col.o = c(rainbow( 64, start = 2/6, end = 4/6)), col.u =\n",
                "              grey(0:255/255), cutOff = c(0, 1))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Additional neuro-imaging packages\n",
                "There are many R packages designed to manipulate and visualise brain images in R and this tutorial is not exhaustive in any way.\n",
                "***\n",
                "\n",
                "# 3. Visualisation on a dataframe\n",
                "\n",
                "The following files were downloaded for this chapter from https://openneuro.org/datasets/ds003542/versions/1.0.0\n",
                "\n",
                " - data: participants.tsv\n",
                " \n",
                " - description: participants.json\n",
                " \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read in downloaded data \n",
                "df <- read.table(\"participants.tsv\", sep=\"\\t\", header=T)\n",
                "\n",
                "# remove space after M & F in sex column\n",
                "df$sex <- str_remove(string = df$sex, pattern = \" \")\n",
                "\n",
                "# check that it worked by comparing the number of rows in the dataset with the number of entries that are either male or female (using the right string pattern)\n",
                "nrow(df) == sum(df$sex == \"M\" | df$sex == \"F\")\n",
                "\n",
                "# Note that some numeric columns are considered as characters when you check out the data structure\n",
                "str(df)\n",
                "# transform columns L1 and Ln so they are numeric\n",
                "df$L1<-as.numeric(df$L1)\n",
                "df$Ln<-as.numeric(df$Ln)\n",
                "# the warning message indicates that the entries include missing values, which are now labeled NA\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The warning message is safe to ignore. It indicates that the entries include missing values, which are now labeled `NA`.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read description file\n",
                "description <- fromJSON(file = \"participants.json\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are going to add some synthetic data. We will calculate whole brain and gray matter volumes, for which we will use the following equations (calculated on segmented open source healthy control data):\n",
                "\n",
                "\\[\n",
                "  (\\operatorname{Whole Brain)} = 1696.06 - 3.34 * (\\operatorname{Age)} \n",
                "\\]\n",
                "\n",
                "\\[\n",
                "  (\\operatorname{GrayMatter)} = 1041.07 - 2.84 * (\\operatorname{Age)} \n",
                "\\]\n",
                "  \n",
                "In addition, we will simulate noise drawn from a normal distribution and add it to the variables.\n",
                "\n",
                "This operation is straightforward in R:\n",
                "\n",
                "- Simulate noise using the `rnorm()` function\n",
                "\n",
                "- Calculate the new variables `whole brain` and `gray matter` as a function of age + the noise\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create noise from a normal distribution to add to the newly create variable\n",
                "set.seed(12)\n",
                "noise<-rnorm(nrow(df), mean = 0, sd = 20)\n",
                "\n",
                "# apply calculation for whole brain \n",
                "df$whole_brain <- (1696.06 - (3.34*df$age)) + noise\n",
                "\n",
                "# regenerate noise\n",
                "set.seed(34)\n",
                "noise<-rnorm(nrow(df), mean = 0, sd = 18)\n",
                "\n",
                "# apply calculation for gray matter\n",
                "df$gray_matter <- (1041.07 - (2.84 * df$age)) + noise\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Explore the dataframes quantitatively\n",
                "\n",
                "Explore the dataframe `df` by creating tables and data summaries:\n",
                "\n",
                "You might find the following functions helpful: `head()`, `summary()`, `table()`, `CreateTableOne()`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# show head() of the df\n",
                "head(df)\n",
                "\n",
                "# describe the data using summary which we use for continuous variables\n",
                "summary(df[,c(\"age\",\"whole_brain\",\"gray_matter\",\"L1\",\"Ln\")])\n",
                "\n",
                "# print tables for binary variables\n",
                "table(df$sex)\n",
                "table(df$group)\n",
                "\n",
                "# show tables for binary variables using tableone package (which is a bit nicer)\n",
                "CreateTableOne(vars = c(\"sex\",\"group\"), data = df)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Display the description file you read in using `print()`\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print description using the str() function which displays the structure of the object\n",
                "print(str(description))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Basic visualisation with ggplot2\n",
                "\n",
                "ggplot is the most popular data visualisation tool in R and it is very flexible. There are loads of great websites explaining the rationale behind ggplots like [this one](https://ggplot2-book.org/index.html) for example.\n",
                "\n",
                "Plot the distribution of the age column with a histogram using the following input:\n",
                "\n",
                "- Initiate a ggplot `ggplot()` for which you specify the data `data = df` and the column of interest to be plotted `aes(age)` (aes stands for aesthetics that appear in your plot)\n",
                "\n",
                "- Indicate that you want a histogram `geom_histogram` and add specifications of what the histogram is supposed to look like.\n",
                "\n",
                "- If you would like specific colours, you can find them [here](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf)\n",
                "\n",
                "- Name x and y axes with `xlab` and `ylab`\n",
                "\n",
                "- Chose a theme to make it look more pretty `theme_bw`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "age_plot<-    ggplot(data = df, aes(age))+\n",
                "                geom_histogram(binwidth = 5, fill = \"bisque2\", col = \"black\")+\n",
                "                xlab(\"Age in bins of 5\")+\n",
                "                ylab(\"Count\")+\n",
                "                theme_bw()\n",
                "\n",
                "age_plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "<br>\n",
                "\n",
                "Next, we will plot the same histogram and stratify it by sex. We use the same code as above, but add one line `facet_grid(~Sex)` to achieve the distinction between male and female.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a new variable that spells out sex\n",
                "df$Sex<-ifelse(df$sex == \"M\", \"Male\", \"Female\")\n",
                "\n",
                "# re-run the same code with facet_grid\n",
                "age_sex_plot<-    ggplot(data = df, aes(age))+\n",
                "                geom_histogram(aes(fill= Sex), binwidth = 5, col = \"black\")+\n",
                "                xlab(\"Age in bins of 5\")+\n",
                "                ylab(\"Count\")+\n",
                "                theme_bw()+ \n",
                "                facet_grid(~Sex)\n",
                "\n",
                "age_sex_plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "<br>\n",
                "\n",
                "Use the same code and explore how the plots change when you change the number of bins!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bins<-seq(from = 3, to = 10, by = 3)\n",
                "\n",
                "# re-run the same code with different bins \n",
                "for(i in bins){\n",
                "  # define name for your plot to be saved under\n",
                "  plot_name <- paste0(\"plot_bins\",i)\n",
                "  \n",
                "  # create the plot with i as the number of bins\n",
                "  plot <- ggplot(data = df, aes(age))+\n",
                "                geom_histogram(aes(fill= Sex), binwidth = i, col = \"black\")+\n",
                "                xlab(paste0(\"Age in bins of \",i))+\n",
                "                ylab(\"Count\")+\n",
                "                theme_bw()+ \n",
                "                facet_grid(~Sex)\n",
                "  \n",
                "  # assign your plot name to the plot\n",
                "  assign(plot_name,plot)\n",
                "}\n",
                "\n",
                "# display the plots created\n",
                "plot_bins3\n",
                "plot_bins6\n",
                "plot_bins9\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "<br>\n",
                "\n",
                "Let's integrate what we have learned! Can you make the following two plots:\n",
                "<br>\n",
                "\n",
                "1) Display the distribution of the `whole_brain` column using the ggplot argument `geom_density()`.\n",
                "\n",
                "2) Display the relationship between `age` and `whole_brain` in a scatterplot using `geom_point()`.\n",
                "\n",
                "3) The plots should be coloured in red.\n",
                "\n",
                "4) They should be combined so that they sit on top of each other.\n",
                "\n",
                "HINT: If you are not working with stratified data, `cowplot` is a nice package to combine multiple plots in figure. First, you create your plots and save them to your workspace. Second, you use the function `plot_grind()` to arrange your plots. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create density plot for the whole brain measure\n",
                "whole_brain_density<-\n",
                "ggplot(data = df, aes(whole_brain))+\n",
                "          geom_density(col=\"red3\", size = 2)+\n",
                "          xlab(\"Whole brain\")+\n",
                "          ylab(\"Density\")+\n",
                "          theme_bw()\n",
                "  \n",
                "# create a scatterplot that contrasts age and whole_brain\n",
                "age_whole_brain<-\n",
                "  ggplot(data = df, aes(x = age, y = whole_brain))+\n",
                "  geom_point(col = \"red3\", size = 1.5)+\n",
                "  xlab(\"Age\")+\n",
                "  ylab(\"Whole Brain\")+\n",
                "  theme_bw()+\n",
                "  geom_smooth(aes(x = age, y = whole_brain, col = \"red\"),method = lm, se = TRUE)+\n",
                "  theme(legend.position = \"none\")+\n",
                "  stat_cor(method=\"pearson\",cor.coef.name=\"r\",size=4.5,position = \"identity\", label.x.npc = 0.65)\n",
                "\n",
                "library(cowplot)\n",
                "\n",
                "plot_grid(whole_brain_density, age_whole_brain, nrow = 2, ncol = 1, labels = c(\"A\",\"B\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Looping with ggplot\n",
                "\n",
                "Sometimes, you might like to create plots that are very similar in that they take the same ggplot arguments, but they use different input variables. Instead of re-writing the code every time, you can using a `for` loop to do the work for you. \n",
                "However, you must set up a data structure for this to work. We will see how this is done, by aiming to plot all possible combinations of `age`, `whole_brain` and `Ln`.\n",
                "\n",
                "- Create a `list()` that contains all the possible combinations between the three variables.\n",
                "\n",
                "- Loop over this list, using the stored variable names and inputs in your ggplot. \n",
                "\n",
                "- Save the output of the loop in another list, and pass the list to `plot_grid()` to display all the plots simultaneously. \n",
                "\n",
                "*This certainly seems to be less straightforward than it is in Python*\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# build a list containing possible combinations of age, whole_brain, and Ln\n",
                "var_list<-vector(mode = \"list\", length = 9)\n",
                "trait1<-c(\"age\", \"whole_brain\",\"Ln\")\n",
                "trait2<-c(\"age\", \"whole_brain\",\"Ln\")\n",
                "\n",
                "k <- 0\n",
                "while(k<9)\n",
                "for(i in trait1){\n",
                "  for(j in trait2){ \n",
                "    k <- k+1\n",
                "    var_list[[k]][1]<-i\n",
                "    var_list[[k]][2]<-j\n",
                "  }\n",
                "}\n",
                "\n",
                "\n",
                "\n",
                "# make list in which to save the plots\n",
                "plot_list = list()\n",
                "for(i in 1:length(var_list)){\n",
                "  rm(plot)\n",
                "  plot<-ggplot(data = df)+\n",
                "          geom_point(aes_string(x = var_list[[i]][1], y = var_list[[i]][2]), col = \"blue\", size = 1.5)+\n",
                "          geom_smooth(aes_string(x = var_list[[i]][1], y = var_list[[i]][2]),method = lm, se = TRUE)+\n",
                "          theme(legend.position = \"none\")+\n",
                "          theme_bw()+\n",
                "          xlab(var_list[[i]][1])+\n",
                "          ylab(var_list[[i]][2])\n",
                "  plot_list[[i]]<-plot\n",
                "}\n",
                "\n",
                "\n",
                "plot_grid(plotlist=plot_list)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br>\n",
                "*You will get warnings because the dataframe contains missing data, it's nothing to worry about.*\n",
                "\n",
                "## Pairplots\n",
                "You may have noticed that creating the multiple plots above was not straightforward and the diagonal figures are not particularly useful. So called \"pairplots\" aim to maximise the information and replace the diagonals by density distributions. To save you the work, fellow R programmers have created a function in the `GGally` package that creates pairplots for you in one line of code! \n",
                "<br>\n",
                "\n",
                "Explore the `ggpairs` function and attempt to stratify the plot by sex using the `mapping` argument!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(GGally)\n",
                "\n",
                "ggpairs(df, columns = c(\"age\",\"whole_brain\",\"Ln\"), mapping = aes(color=Sex), columnLabels = c(\"Age\",\"Whole brain\",\"Ln\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Heatmaps\n",
                "Heatmaps are a popular choice for data visualisation when pairplots, for example, would become too big and busy. A heatmap is a n-by-n matrix which colour codes the correlations found between your variables of interest.\n",
                "To create a heatmap, you will have to calculate a correlation matrix using `cor()`, and if you use the `heatmap()` function in R, the job is done in one line. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# heatmap in ggplot\n",
                "df_matrix<-cor(df[c(\"age\",\"L1\",\"Ln\",\"whole_brain\",\"gray_matter\")],df[c(\"age\",\"L1\",\"Ln\",\"whole_brain\",\"gray_matter\")], use = \"complete.obs\")\n",
                "\n",
                "heatmap(df_matrix)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "However, you might want to change the look of your heatmap. Using ggplot gives you that flexibility.\n",
                "Why don't you try to use what you have learned, and apply it to a ggplot with the `geom_tile` argument?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# do it in ggplot\n",
                "get_lower_tri<-function(cormatrix){\n",
                "    cormatrix[upper.tri(cormatrix)] <- NA\n",
                "    return(cormatrix)\n",
                "  }\n",
                "\n",
                "df_heatmap<-get_lower_tri(df_matrix)\n",
                "df_heatmap<-reshape2::melt(df_heatmap)\n",
                "\n",
                "ggheatmap<-ggplot(data=df_heatmap, aes(Var1,Var2,fill=value))+\n",
                "  geom_tile()+\n",
                "  theme_minimal()+\n",
                "  scale_fill_gradient2(low=\"gold4\",high=\"darkorange3\",mid =\"gold\",\n",
                "                         midpoint=0,limit=c(-1,1),na.value=\"white\",name=\"Correlations\")+\n",
                "  coord_fixed()+\n",
                "  xlab(\"\")+\n",
                "  ylab(\"\")\n",
                "\n",
                "ggheatmap\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<br/>\n",
                "<br/>\n",
                "\n",
                "**Closing remark**\n",
                "The static website displaying this code was created in Rmarkdown, and the jupyter notebook was created using the `rmd2jupyter()` function provided by the [mkearney/rmd2jupyter package](https://laptrinhx.com/convert-rmd-rmarkdown-to-ipynb-jupyter-notebook-574451390/).\n",
                "\n",
                "***\n",
                "\n",
                "\n",
                "\n",
                "<br/>\n",
                "\n",
                "\n",
                "\n",
                "**Acknowledgements and References**\n",
                "Thanks to Stijn for creating the content of this tutorial!\n",
                "\n",
                "We express our sincere gratitude to Kshipra Gurunandan, Manuel Carreiras and Pedro M. Paz-Alonso for making this data open source, and thus allowing us to make this tutorial. The citation, references and contact details can be found below:\n",
                "\n",
                "**Dataset Citation**\n",
                "Kshipra Gurunandan and Manuel Carreiras and Pedro M. Paz-Alonso (2021). Adult language learners. OpenNeuro. [Dataset] doi: 10.18112/openneuro.ds003542.v1.0.0\n",
                "\n",
                "\n",
                "<br/>\n",
                "\n",
                "**Publications using this dataset:**\n",
                "\n",
                "[1] Gurunandan, K., Carreiras, M., & Paz-Alonso, P.M. (2019). Functional plasticity associated with language learning in adults. NeuroImage, 201. Doi:10.1016/j.neuroimage.2019.116040\n",
                "- Data: comprehension task from this dataset.\n",
                "- Summary: In this work, we examined different dimensions of learning-dependent plasticity of reading and speech comprehension in intermediate and advanced adult language learners, i.e. after the initial effort of adult second language learning, do language networks continue to change with increasing proficiency?\n",
                "\n",
                "[2] Gurunandan, K., Arnaez-Telleria, J., Carreiras, M., & Paz-Alonso, P.M. (2020). Converging evidence for differential specialization and plasticity of language systems. Journal of Neuroscience, 40(50), 9715-9724. Doi:10.1523/JNEUROSCI.0851-20.2020\n",
                "- Data: comprehension and production tasks from this dataset + comprehension and production tasks from a longitudinal dataset (available at [add link]).\n",
                "- Summary: In this work, we put together cross-sectional and longitudinal studies in a comprehensive examination of the flexibility of lateralisation, i.e. is hemispheric lateralisation of language processing fixed in early childhood or can it change with later language learning?\n",
                "\n",
                "\n",
                "Contact information of owners of the datasets\n",
                "\n",
                "For any questions to the authors that made this dataset open-access to everyone:\n",
                "\n",
                "  - Kshipra Gurunandan k.gurunandan@bcbl.eu\n",
                "  \n",
                "  - Pedro M. Paz-Alonso p.pazalonso@bcbl.eu\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
